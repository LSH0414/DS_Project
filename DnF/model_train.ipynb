{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xti4EHgWoK-H"
      },
      "source": [
        "# 1. SFT\n",
        "## 던파에 대한 내용을 아는 모델을 만들자!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ1nlpAX00Hm"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)\n"
      ],
      "metadata": {
        "id": "FhZqxm-nMbbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define argment\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--output_dir', type=str, default='./output_1_SFT')\n",
        "parser.add_argument('--data_path', type=str, default='/content/drive/MyDrive/ds_study/던파_story/data/train_data/dnf_story_forTrain_tokenFor1024.jsonl')\n",
        "parser.add_argument('--model', type=str, default='gpt2', choices=['gpt2', 'bloom', 'opt'])\n",
        "parser.add_argument('--pretrain', type=str, default=None)\n",
        "parser.add_argument('--max_epochs', type=int, default=10)\n",
        "parser.add_argument('--batch_size', type=int, default=8)\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# for test\n",
        "args.max_epochs = 3\n",
        "args.pretrain = 'EleutherAI/polyglot-ko-1.3b'  # pretrained 모델 가져오기\n",
        "args.verbose = True\n",
        "\n",
        "print(args)\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)"
      ],
      "metadata": {
        "id": "J1cjogjAMZV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Hhcft4xxVSX"
      },
      "outputs": [],
      "source": [
        "# 모델, 토크나이저\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.pretrain)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(args.pretrain, quantization_config=bnb_config, device_map={\"\":0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBi9P3XqLr6E"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# load SFT train data\n",
        "data= load_dataset(\"json\", data_files=args.data_path)\n",
        "\n",
        "# fitting prefix form\n",
        "data = data.map(\n",
        "    lambda x: {'text': f\"### 질문: {x['prompt']}\\n\\n### 답변: {x['completion']}<|endoftext|>\" }\n",
        ")\n",
        "\n",
        "# encoding text\n",
        "data = data.map(lambda samples: tokenizer(samples[\"text\"]), batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbrlGRBPUtU9"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo0v-HGvUzHk"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXgk5cbqU0U_"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZvA-1K8U45D"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=data[\"train\"],\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=args.batch_size,\n",
        "        gradient_accumulation_steps=2,\n",
        "        learning_rate=1e-4,\n",
        "        fp16=True,\n",
        "        logging_steps = 100,\n",
        "        save_steps = 100,\n",
        "        output_dir=args.out_dir,\n",
        "        optim=\"paged_adamw_4bit\",\n",
        "        save_total_limit = 3,\n",
        "        seed = random_seed\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# load checkpoint, continue train\n",
        "# trainer.train(resume_from_checkpoint = '/content/drive/MyDrive/ds_study/던파_story/output_1_SFT/checkpoint-2800')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRvZnJjJ3_wg"
      },
      "outputs": [],
      "source": [
        "# Model Save\n",
        "trainer.save_model(args.out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_jBSuNK0qAy"
      },
      "source": [
        "### Generate Text finetuning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3883vXY4ZnI"
      },
      "outputs": [],
      "source": [
        "# if restart session have to run\n",
        "\n",
        "# import torch\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# from peft import PeftModel, PeftConfig\n",
        "\n",
        "\n",
        "# peft_model_id = args.out_dir\n",
        "# config = PeftConfig.from_pretrained(peft_model_id)\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
        "# )\n",
        "# model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, quantization_config=bnb_config, device_map={\"\":0})\n",
        "# model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l_FTMj20yYc"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def gen(x):\n",
        "    start_time = time.time()\n",
        "    gened = model.generate(\n",
        "        **tokenizer(\n",
        "            f\"### 질문: {x}\\n\\n### 답변:\",\n",
        "            return_tensors='pt',\n",
        "            return_token_type_ids=False\n",
        "        ).to(0),\n",
        "        num_beams=3,\n",
        "        no_repeat_ngram_size=4,\n",
        "        top_p = 0.9,\n",
        "        max_new_tokens=256,\n",
        "        early_stopping=True,\n",
        "        do_sample=True,\n",
        "        eos_token_id=2,\n",
        "    )\n",
        "    print(tokenizer.decode(gened[0]))\n",
        "    print(time.time() - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns5iMuU1s6tg"
      },
      "outputs": [],
      "source": [
        "# gen('건강하게 살기 위한 세 가지 방법은?')\n",
        "list_prompt = ['일곱 사도들에 대해서 알려줘',\n",
        "               '아라드 대륙에 대해서 설명해줘.',\n",
        "               '바칼이 천계를 공격한 이유는?.',\n",
        "               '게이볼그 프로젝트에 대해서 요약해주세요'\n",
        "               ]\n",
        "\n",
        "for input in list_prompt:\n",
        "  gen(input)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNLwZDOooeyN"
      },
      "source": [
        "# 2. RM\n",
        "\n",
        "## 좋은 대답을 평가하는 모델을 만들자!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tikow03TKmT6"
      },
      "source": [
        "## 설치 모듈"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDqNxYz6_L1S"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q datasets\n",
        "!pip install jsonlines\n",
        "!pip install trl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgGMlXq9Kpk9"
      },
      "source": [
        "## 좋은 대답을 할 수 있게 유도하는 보상 모델을 만들자!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr_6EnpCpMOK"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, TaskType\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import BitsAndBytesConfig, TrainingArguments\n",
        "from trl import RewardTrainer, RewardConfig\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoacED2l-ijC"
      },
      "outputs": [],
      "source": [
        "# define argment\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--output_dir', type=str, default='/content/drive/MyDrive/ds_study/던파/output_2_RM')\n",
        "parser.add_argument('--data_path_RM', type=str, default='/content/drive/MyDrive/ds_study/던파_story/data/train_data/kochatgpt_2_RM.jsonl')\n",
        "parser.add_argument('--df_data_path_RM', type=str, default='/content/drive/MyDrive/ds_study/던파_story/data/train_data/dnf_data_RM.json')\n",
        "parser.add_argument('--strategy',\n",
        "                    choices=['naive', 'ddp', 'colossalai_gemini', 'colossalai_zero2'],\n",
        "                    default='naive')\n",
        "parser.add_argument('--model', type=str, default=None)\n",
        "parser.add_argument('--pretrain', type=str, default=None)\n",
        "parser.add_argument('--dataset', type=str, default='Dahoas/rm-static')\n",
        "parser.add_argument('--save_path', type=str, default='rm_ckpt.pth')\n",
        "parser.add_argument('--max_epochs', type=int, default=10)\n",
        "parser.add_argument('--batch_size', type=int, default=4)\n",
        "parser.add_argument('--lora_rank', type=int, default=0, help=\"low-rank adaptation matrices rank\")\n",
        "parser.add_argument('--max_len', type=int, default=512)  # wygo 추가\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# for test\n",
        "args.max_epochs = 3\n",
        "args.pretrain = \"EleutherAI/polyglot-ko-1.3b\" #huggingFace\n",
        "# args.pretrain = 'skt/kogpt2-base-v2'\n",
        "\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNc3ODBc-n11"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(args.pretrain, quantization_config=bnb_config, device_map={\"\":0}, num_labels=1)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.pretrain)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUNBFUZj-5BO",
        "outputId": "4a1e5b02-19ef-4292-c0e9-6e6b431df061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## df_data check ##\n",
            "{'prompt': '바다와 전쟁의 흔적, 그리고 마계의 사도들에 대한 이야기를 요약 해주세요.', 'completion_0': '소녀는 처음으로 넓은 바다를 보고 감탄하며 그 아름다움에 매료되었습니다. 그러나 그녀가 바라본 바다 주변의 섬은 과거 전쟁으로 황폐해진 곳이었습니다. 이곳에서 바다와 다른 풍경을 이루는 활화산이 있는 섬에 사도 안톤이 존재했다는 사실에 놀라움을 감추지 못했습니다. 소녀는 마계와 천계를 이어주는 통신 장치를 통해 연결된 리아 리히터와 통신을 하며, 자신이 마계에서 사라진 사도들을 찾는 데에 중요한 역할을 할 것이라는 기대감을 주고받습니다. 그러나 갑자기 차원의 틈이 닫혀 통신은 끊기고, 이제 그녀는 천계와 마계의 경계에서 불확실한 미래를 향해 자신의 역할을 다하기 위해 각오를 다집니다.', 'completion_1': '바다를 처음 본 소녀는 과거 전쟁터였던 섬의 아름다움에 놀랍니다. 그리고 통신기를 통해 리아와 사도 안톤의 존재 및 상황을 나누며 정보를 주고받지만, 차원의 틈이 닫혀 다시 연락을 기다려야 하는 상황에 처하게 됩니다.', 'completion_2': '바다에 감탄한 소녀가 마계의 사도들과 관련한 중요한 통신을 하다 차원의 틈이 닫혀 소통이 끊깁니다.', 'ranking': [0, 2, 1]}\n",
            "## data check ##\n",
            "{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?', 'completion_0': 'Allow me to answer your question. I know that you are curious about me.', 'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.', 'completion_2': '라이언에게 말했다.', 'ranking': [2, 1, 0]}\n"
          ]
        }
      ],
      "source": [
        "# make ranking data to chosen, rejetced data\n",
        "rm_data_combine = []\n",
        "with open(args.df_data_path_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
        "    list_data_dict = json.load(json_file)\n",
        "\n",
        "    print('## df_data check ##')\n",
        "    print((list_data_dict[0]))\n",
        "\n",
        "rm_data_combine += list_data_dict\n",
        "\n",
        "with open(args.data_path_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
        "    list_data_dict = json.load(json_file)\n",
        "\n",
        "    print('## data check ##')\n",
        "    print((list_data_dict[0]))\n",
        "\n",
        "rm_data_combine += list_data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lvWlDkRK5aI",
        "outputId": "ee9f7dd5-e20e-49cc-dddf-f9b5a0fa0cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before data num: 12988\n",
            "after  data num: 38964\n",
            "data example: \n",
            "{'prompt': \"'정복자 카시야스'는 누구인가요?\", 'chosen': \"'정복자 카시야스'는 호전적인 귀면족의 일원으로 마계의 에컨에서 태어났으며, 강한 기운을 찾아 전투를 치르는 존재입니다. 이 종족은 평범한 인간보다 약 1.5배 큰 체구를 가지고 있으며, 두 자루의 검을 사용하여 싸웁니다. 카시야스는 사도 중에서도 최고의 전투 실력을 자랑하지만, 제 1사도인 숙명의 카인에게는 패하여 더 강해지기 위해 마계 소환사와 계약을 맺고 아라드 대륙으로 건너옵니다. 새로운 세계에서 새로운 적들과의 대결을 통해 자신을 강화하며, 항상 새로운 도전을 기대하는 낙천주의자입니다. 성우 안장혁이 이 캐릭터의 목소리를 담당했습니다.\", 'rejected': \"'정복자 카시야스'는 마계에 살던 귀면족으로 강함을 추구하여 아라드로 온 전사입니다. 최강이라는 명성에 걸맞게 다양한 전투 경험을 쌓으나 1사도에게 패배하고, 이를 계기로 끝없이 강해지고자 합니다. 그는 또한 끊임없는 새로운 도전을 좋아하는 낙천적 기질을 가지고 있습니다.\"}\n"
          ]
        }
      ],
      "source": [
        "total_data_ranking2chosen = []\n",
        "for tmp in rm_data_combine:\n",
        "    one_data_ranking2chosen = []\n",
        "\n",
        "    # data 1) 0 VS 1\n",
        "    data = {}\n",
        "    data['prompt'] = tmp['prompt']\n",
        "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
        "        data['chosen'] = tmp['completion_0']\n",
        "        data['rejected'] = tmp['completion_1']\n",
        "    else:\n",
        "        data['chosen'] = tmp['completion_1']\n",
        "        data['rejected'] = tmp['completion_0']\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "\n",
        "    # data 2) 0 VS 2\n",
        "    data = {}\n",
        "    data['prompt'] = tmp['prompt']\n",
        "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
        "        data['chosen'] = tmp['completion_0']\n",
        "        data['rejected'] = tmp['completion_2']\n",
        "    else:\n",
        "        data['chosen'] = tmp['completion_2']\n",
        "        data['rejected'] = tmp['completion_0']\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "    # data 1) 1 VS 2\n",
        "    data = {}\n",
        "    data['prompt'] = tmp['prompt']\n",
        "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
        "        data['chosen'] = tmp['completion_1']\n",
        "        data['rejected'] = tmp['completion_2']\n",
        "    else:\n",
        "        data['chosen'] = tmp['completion_2']\n",
        "        data['rejected'] = tmp['completion_1']\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "\n",
        "\n",
        "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
        "\n",
        "print('before data num: %d'%(len(rm_data_combine)))\n",
        "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
        "print('data example: \\n%s'%total_data_ranking2chosen[45])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "77f58412e1044f7aa0f1256da90f76fe",
            "59a7e361fdb24ea5a1a90c4f3189ca7e",
            "38be7f7a4d754b368de499ec2039b7db",
            "cab1d507641b48c08fbbab2401a12e93",
            "818b62151a8f4a788c0e8602f9bac520",
            "9797548d54c443cb91bbf6ae1a9d88ad",
            "d1585e5512684ee69bed4cc3015e91fe",
            "918f913851b645748089ae538e0aaccd",
            "10946261c9e24c65a9d27a0b008a8880",
            "d3f3e9f11cd140c099aca4d9954f10e6",
            "a63cbeef8691465b9b940bbdb4700350",
            "a92b6aa957474e9597f5235a8621c93b",
            "f4e2e86fa354427aad7681618b626913",
            "41bc288374e840febe9f227ad020632b",
            "bc4399242fb24381b3185f3f17df9400",
            "f112dac7b4c94a9d900036c0cb3eec01",
            "6486d4317f1b4bdcbca2eabf1a8bad3e",
            "f080dc4d1c164d3bbacd40f84a764ad5",
            "15e939b0a0e64f9096642e93aeccd0ba",
            "e7c43b55865a4fb58ed9a0532f08bf91",
            "9f4bad9577f64dbd9acc90fb714bf9b5",
            "1a2eeb2026b444bdaf964e10286f1f80"
          ]
        },
        "id": "OSy-G3a5-9aj",
        "outputId": "92a75594-59e0-41fd-e85f-b912e1fdcf91"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77f58412e1044f7aa0f1256da90f76fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/35964 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a92b6aa957474e9597f5235a8621c93b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def formatting_func(examples):\n",
        "    kwargs = {\"padding\": \"max_length\", \"truncation\": True, \"max_length\": 512, \"return_tensors\": \"pt\"}\n",
        "    chosen = examples[\"prompt\"] + \"\\n\" + examples[\"chosen\"]\n",
        "    rejected = examples[\"prompt\"] + \"\\n\" + examples[\"rejected\"]\n",
        "\n",
        "    tokens_chosen = tokenizer.encode_plus(chosen, **kwargs)\n",
        "    tokens_rejected = tokenizer.encode_plus(rejected, **kwargs)\n",
        "\n",
        "    return {\n",
        "        \"input_ids_chosen\": tokens_chosen[\"input_ids\"][0], \"attention_mask_chosen\": tokens_chosen[\"attention_mask\"][0],\n",
        "        \"input_ids_rejected\": tokens_rejected[\"input_ids\"][0], \"attention_mask_rejected\": tokens_rejected[\"attention_mask\"][0]\n",
        "    }\n",
        "from datasets import Dataset\n",
        "train_data = Dataset.from_list(total_data_ranking2chosen[:-3000])\n",
        "eval_data = Dataset.from_list(total_data_ranking2chosen[-3000:])\n",
        "\n",
        "train_data.to_pandas()\n",
        "eval_data.to_pandas()\n",
        "\n",
        "train_dataset = train_data.map(formatting_func)\n",
        "eval_dataset = eval_data.map(formatting_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBSEEJkgpjUr"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias = 'none'\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAE6i8YfqvJA",
        "outputId": "6e34eff5-7c38-4eae-831c-801b2ff6abb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1574912 || all params: 667803648 || trainable%: 0.2358345907089145\n"
          ]
        }
      ],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIm3znKd_E6-"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    if param.requires_grad:\n",
        "        param.data = param.data.to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMYb9tqoW4K0"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cfFnk2Poh5S"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=8,\n",
        "        learning_rate=1e-4,\n",
        "        fp16=True,\n",
        "        logging_steps = 100,\n",
        "        save_steps = 100,\n",
        "        output_dir=args.output_dir,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        save_total_limit = 3,\n",
        "        seed = random_seed\n",
        "    )\n",
        "\n",
        "\n",
        "trainer = RewardTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Load checkpoint, contiue train\n",
        "# trainer.train(resume_from_checkpoint = '/content/drive/MyDrive/ds_study/던파_story/output_2_RM/checkpoint-3000')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGCREYjIrrEh"
      },
      "outputs": [],
      "source": [
        "# model save\n",
        "model.save_pretrained(args.output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xt5-RWIMOf7"
      },
      "source": [
        "### Check Reward Score, RM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbwkc6ct1wmr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForSequenceClassification\n",
        "\n",
        "# inference Score\n",
        "def inference_RM(model, rm_model, input_text):\n",
        "\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
        "        torch.cuda.current_device())\n",
        "\n",
        "    output = model(input_ids)\n",
        "\n",
        "    output_reward = output.cpu().detach().numpy()[0]\n",
        "\n",
        "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
        "    print('df_reward score: %.1f'%(df_output_reward))\n",
        "\n",
        "    return output_reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5Iw3jq0_uJ5",
        "outputId": "ea747ec0-2c48-4a05-c93c-15007a09e878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REWARD MODEL\n",
            "input: 한국에서 사는 것은 행복한 일입니다.\n",
            "reward score: 1.2\n",
            "df_reward score: 0.1\n",
            "\n",
            "REWARD MODEL\n",
            "input: 왜 점수가 안바뀌는거죠?\n",
            "reward score: 1.2\n",
            "df_reward score: 0.1\n",
            "\n",
            "REWARD MODEL\n",
            "input: 융합형 핀드는 불 속성과 물 속성의 속성을 가지고 있습니다. 이 두 속성의 융합으로 인해 융합형 핀드는 정신적으로 불안한 상태에 놓여있지만, 불 속성의 성격과 물 속성의 성격을 모두 가지는 특징을 가지고 있습니다.\n",
            "reward score: 1.1\n",
            "df_reward score: 0.1\n",
            "\n",
            "REWARD MODEL\n",
            "input: '플레인 : 인퍼널'에서 이단심판관들은 위장자가 된 세계에서 자신들을 저주받은 불꽃이라 칭하며 자신들만의 길을 걷기 시작했습니다. 이들은 혼돈의 신에게 복종하지 않았지만, 여전히 신을 향한 믿음만큼은 갖고 있었습니다. 그러나 위장자의 기운으로 인해 불꽃이 검보라빛으로 변하면서 더욱 강력해졌습니다. 마침내 모든 위장자를 소멸시키고 아라드에 평화를 가져다줬습니다.\n",
            "reward score: 1.2\n",
            "df_reward score: 0.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "rm_adapter = args.output_dir\n",
        "origin_model = \"EleutherAI/polyglot-ko-1.3b\" #huggingFace\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    rm_adapter,\n",
        "    quantization_config=bnb_config,\n",
        "    num_labels=1)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(origin_model)\n",
        "\n",
        "\n",
        "input_texts = ['한국에서 사는건 어떤가요?\\n한국에서 사는 것은 행복한 일입니다.',\n",
        "               '왜 점수가 안바뀌는거죠?\\n제가 대답할 수 있는 질문이 아닙니다.',\n",
        "               '핀드에 대해서 알려줘\\n융합형 핀드는 불 속성과 물 속성의 속성을 가지고 있습니다. 이 두 속성의 융합으로 인해 융합형 핀드는 정신적으로 불안한 상태에 놓여있지만, 불 속성의 성격과 물 속성의 성격을 모두 가지는 특징을 가지고 있습니다.',\n",
        "               ]\n",
        "\n",
        "for input_text in input_texts:\n",
        "  print('-'*70)\n",
        "  inference_RM(model, rm_model, input_text=input_text)\n",
        "  torch.cuda.empty_cache()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQVVpX9OgeK9"
      },
      "source": [
        "# 3.PPO\n",
        "## PPO를 활용해 더 좋은 대답을 하도록 학습시키자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNFZowQ-MM7c"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q datasets\n",
        "!pip install trl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "et467CKEFEEI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H0QOJ-d7NYk4"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForSequenceClassification\n",
        "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
        "from trl.core import respond_to_batch\n",
        "from peft import LoraConfig\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xiV3NhtGPV_y"
      },
      "outputs": [],
      "source": [
        "PROMPT_TEXT = \"### 질문: {txt}\\n\\n### 답변: \"\n",
        "\n",
        "# make dataset PPO\n",
        "def build_dataset(dataset_path, tokenizer):\n",
        "\n",
        "  ds = load_dataset('json', data_files = dataset_path)\n",
        "  tmp = []\n",
        "  for p in ds['train']:\n",
        "    if p['prompt'] != '':\n",
        "      tmp.append(p)\n",
        "  ds = Dataset.from_list(tmp)\n",
        "\n",
        "  def tokenize(sample):\n",
        "    prompt = PROMPT_TEXT.format(txt = sample['prompt'])\n",
        "    sample['input_ids'] = tokenizer.encode(prompt)\n",
        "    sample['query'] = prompt\n",
        "    return sample\n",
        "\n",
        "  ds = ds.map(tokenize, batched=False)\n",
        "  ds.set_format(type='torch')\n",
        "  return ds\n",
        "\n",
        "# make input stlye SFT\n",
        "def make_input(txt):\n",
        "  prompt_text = PROMPT_TEXT.format(txt = txt)\n",
        "  encode = tokenizer(prompt_text, return_token_type_ids=False, return_tensors='pt').to('cuda')\n",
        "  return encode\n",
        "\n",
        "# 보상모델 체크\n",
        "def inference_RM(model, input_text):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to('cuda')\n",
        "\n",
        "    output = model(input_ids)\n",
        "\n",
        "    output_reward = (output.logits.cpu().detach().numpy())\n",
        "\n",
        "    return torch.Tensor(output_reward[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MufwGG0gd9P"
      },
      "outputs": [],
      "source": [
        "model_name = \"/content/drive/MyDrive/ds_study/던파_story/output_1_SFT/model_QnA_FIN2\"\n",
        "rm_adapter_id = \"/content/drive/MyDrive/ds_study/던파_story/output_2_RM/RM_FIN\"\n",
        "origin_model = \"EleutherAI/polyglot-ko-1.3b\" #huggingFace\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# PPO adapter\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Load SFT Model\n",
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
        "    model_name,\n",
        "    peft_config=lora_config,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "# QLoRA를 통한 로드 모델은 deepcopy가 구현되지 않음 직접 하나 더 불러와야함\n",
        "# model_ref = create_reference_model(model) # <--- TRL패키지에서도 copy.deepcopy()를 사용해 모델을 복사하고 있기 때문에 작동하지 않음. 이유는 QLoRA를 통한 로드를 고려하지 않았기 때문 수정진행중이라는 github issue확인.\n",
        "model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
        "    model_name,\n",
        "    peft_config=lora_config,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "# Load RM\n",
        "rm_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    rm_adapter_id,\n",
        "    quantization_config=bnb_config,\n",
        "    num_labels=1)\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(origin_model)\n",
        "\n",
        "# model to cuda\n",
        "# model.to('cuda')\n",
        "# model_ref.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-9KddGv8M1w"
      },
      "outputs": [],
      "source": [
        "# load PPO dataset\n",
        "rm_jsonl_path= '/content/drive/MyDrive/ds_study/던파_story/data/train_data/dnf_data_RM.json'\n",
        "dataset = build_dataset(rm_jsonl_path, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iDyonWtmLWnr"
      },
      "outputs": [],
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
        "\n",
        "# initialize trainer\n",
        "ppo_config = PPOConfig(\n",
        "    batch_size=2,\n",
        ")\n",
        "ppo_trainer = PPOTrainer(ppo_config, model, model, tokenizer, dataset=dataset, data_collator = collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wXw0uFP_z1aQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc107c9e-205d-450a-c6bc-ba95fc992936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:434: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "131it [21:33,  9.89s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -4.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "643it [1:44:43,  9.72s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -1.27 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "697it [1:53:27,  9.74s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -7.09 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "1123it [3:02:37,  9.82s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -6.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "1284it [3:28:40,  9.71s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -5.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "1319it [3:34:20,  9.67s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -9.53 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "1455it [3:56:39,  9.82s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -7.24 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "1505it [4:04:55,  9.96s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -1.68 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "1722it [4:40:34,  9.82s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -7.48 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "2281it [6:11:53,  9.76s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -5.93 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "2677it [7:16:40,  9.78s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -7.82 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "2713it [7:22:32,  9.74s/it]/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -5.94 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "2767it [7:31:20,  9.79s/it]\n"
          ]
        }
      ],
      "source": [
        "step = 0\n",
        "\n",
        "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "  query = batch['query']\n",
        "  query_tensors = batch[\"input_ids\"]\n",
        "  query_tensors = [tensor for tensor in query_tensors]\n",
        "  query_encode = make_input(query)\n",
        "\n",
        "  # get model response\n",
        "  response_tensors = []\n",
        "  response_tensors.append(gen(query_encode, model))\n",
        "  batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
        "\n",
        "  # get RM score\n",
        "  rm_inputs = [q + '\\n' + r for q, r in zip(batch[\"query\"], batch[\"response\"])] # query_txt + '\\n' + tokenizer.decode(response_tensor)\n",
        "  rewards = []\n",
        "  for rm_input in rm_inputs:\n",
        "    rewards.append(inference_RM(rm_model, rm_input))\n",
        "\n",
        "  # PPO\n",
        "  stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
        "  ppo_trainer.log_stats(stats, batch, rewards)\n",
        "  step+=1\n",
        "\n",
        "  # make checkpoint\n",
        "  if step % 50 == 0:\n",
        "    checkponit = '/content/drive/MyDrive/ds_study/던파_story/output_3_PPO/checkpoint-' + str(step)\n",
        "    if not os.path.exists(checkponit):\n",
        "      os.makedirs(checkponit)\n",
        "\n",
        "    model.save_pretrained(checkponit)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_kwargs = {\n",
        "    \"min_length\": -1,\n",
        "    'max_new_tokens' : 128,\n",
        "    \"top_p\": 0.95,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "    'eos_token_id' : 2,\n",
        "    'early_stopping' : True,\n",
        "    'num_beams' : 1,\n",
        "    'no_repeat_ngram_size' : 4\n",
        "}\n",
        "epoch = 1\n",
        "TARGET_EPOCH = 1\n",
        "while True:\n",
        "\n",
        "  for train_step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "    queries = batch['query']\n",
        "    query_tensors = batch[\"input_ids\"]\n",
        "    query_tensors = [tensor for tensor in query_tensors]\n",
        "\n",
        "    # get model response\n",
        "    response_tensors = []\n",
        "    for query in (query_tensors):\n",
        "      query_len = len(query)\n",
        "      response = ppo_trainer.generate(query, **generation_kwargs)\n",
        "      end_point = (torch.flip(response.squeeze(), [0]) == 17).nonzero(as_tuple=False)[0] # tokenizer '.' token_id = 17\n",
        "      response_tensors.append(response.squeeze()[:-end_point][query_len:])\n",
        "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
        "\n",
        "    # get RM score\n",
        "    rm_inputs = [q + '\\n' + r for q, r in zip(batch[\"query\"], batch[\"response\"])] # query_txt + '\\n' + tokenizer.decode(response_tensor)\n",
        "    rewards = []\n",
        "    for rm_input in rm_inputs:\n",
        "      rewards.append(inference_RM(rm_model, rm_input))\n",
        "\n",
        "    # break\n",
        "    # PPO\n",
        "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
        "    ppo_trainer.log_stats(stats, batch, rewards)\n",
        "\n",
        "    # make checkpoint\n",
        "    if (train_step+1) % 50 == 0:\n",
        "      checkponit = '/content/drive/MyDrive/ds_study/던파_story/output_3_PPO/checkpoint-' + str(train_step+1)\n",
        "      if not os.path.exists(checkponit):\n",
        "        os.makedirs(checkponit)\n",
        "\n",
        "      model.save_pretrained(checkponit)\n",
        "\n",
        "  # check Epoch\n",
        "  if epoch == TARGET_EPOCH:\n",
        "\n",
        "    print('\\nEpoch 1 FIN\\n')\n",
        "    break\n",
        "  epoch+=1\n",
        "\n"
      ],
      "metadata": {
        "id": "vKPzaIpY3D-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F1kZ_D1-VVTN"
      },
      "outputs": [],
      "source": [
        "out_dir = \"/content/drive/MyDrive/ds_study/던파_story/output_3_PPO/PPO_FIN\"\n",
        "if not os.path.exists(out_dir):\n",
        "      os.makedirs(out_dir)\n",
        "model.save_pretrained(out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc6mtBGrVtkz"
      },
      "source": [
        "### Compare PPO_SFT, ref_SFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sLZSyEXHVyFB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "outputId": "a0721bf1-df42-4ea0-a97c-33645131a26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/16 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:434: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "100%|██████████| 16/16 [03:46<00:00, 14.17s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 query  \\\n",
              "0                      타우킹 샤우타는 누구인가요?   \n",
              "1       '오필리아 베이그란스'는 어떤 종교 집단의 신도인가요?   \n",
              "2             에너지 생산실은 어떤 기능을 가지고 있나요?   \n",
              "3                    '람바녹'은 어떤 사람이었나요?   \n",
              "4                     '머크우드'는 어떤 곳인가요?   \n",
              "5                '플레인 : 코스모핀드'는 무엇인가요?   \n",
              "6              헤블론 바실리움을 만든 주인은 누구인가요?   \n",
              "7   '네빌로 유르겐 행적'에 대해서 어떤 내용을 찾을 수 있나요?   \n",
              "8                 '칠흑의 송곳니'는 어떤 작품인가요?   \n",
              "9               어떤 내용에 대한 요약을 진행하였습니까?   \n",
              "10                      세계는 어떻게 구분되나요?   \n",
              "11                      그렘린은 어떤 종족인가요?   \n",
              "12            '독 제장 비명'에 대한 내용은 무엇인가요?   \n",
              "13         '데스페라도'에 대한 내용을 간단히 설명해주세요.   \n",
              "14          이 비밀 기사들은 어떤 역할을 수행하고 있나요?   \n",
              "15          덴드로이드의 정글은 어떤 내용을 다루고 있나요?   \n",
              "\n",
              "                                    response (before)  \\\n",
              "0    타우킹 사도들은 샤우타를 타우로 부르고, 그들은 그를 타우킹이라 칭합니다. 이들은...   \n",
              "1    '오필리어 베이그란스는 루크를 따르는 자들 중 하나로, 현재는 교단에서 운영하는 ...   \n",
              "2    에너지 생산실은 에너지 저장과 전송의 기능을 가지며, 각 에너지는 다양한 형태로 ...   \n",
              "3    람바녹은 그란플로리스의 주인으로, 검은 성전에 참가하여 모든 무기들을 파괴하고 많...   \n",
              "4    '머크 우드'는 마계를 상징하는 지역 중 하나로, 마계의 중심지인 마계 도시입니다...   \n",
              "5    '플레인: 코스모필스'는 검은 마물의 후예이자 검은 마검사인 코스모 핀드를 지칭합...   \n",
              "6    헤블론의 헤블론을 만든 주인입니다.  헤블롱은 자신을 위해서 죽은 주인을 기리기 ...   \n",
              "7    본문에서는 네빌로 유를 겐트에 남은 마지막 귀족으로 언급하면서 그의 행적을 다루고...   \n",
              "8    '칠흑'은 선계 3대 아트의 하나인 \"칠흑의 분노\"를 주제로 한 작품입니다. 이 ...   \n",
              "9     선민의식이라는 소재를 중심으로 하여, 이는 그의 작품 전반에 흐르는 주요 특징 ...   \n",
              "10  ...본문에는 자세한 설명이 제공되지 않았습니다. 제가 해석한 내용이므로 추가적인 ...   \n",
              "11   그렘린들은 이계의 신수 중 하나입니다. 그들은 종족 특성상 강한 힘을 바탕으로 생...   \n",
              "12   대자연 속에서 피를 흘리며 홀로 죽음을 맞이하는 한 여인의 모습과 그녀의 울음소리...   \n",
              "13   이 검에 깃든 힘은 신과의 약속을 지키기 위해 사용되고 있습니다. 이 검은 죽음의...   \n",
              "14  ...시로코의 예언의 빛과 함께 어둠의 기운을 사용하여 어둠의 기사들이 비밀을 지키...   \n",
              "15   정글에는 다양한 종류의 식물과 곤충들이 서식하고 있습니다. 덴드로이드들은 정글을 ...   \n",
              "\n",
              "                                     response (after)   rewards (before)  \\\n",
              "0    타우킹 타우는 타우타의 조상입니다. 원래는 불을 잘 다루었지만 그 능력이 점차 쇠...   [tensor(0.6245)]   \n",
              "1    '오필리오 베이그란스'()는 황도군에 합류한 후에도 종교 단체에 남아 있었습니다....   [tensor(3.3848)]   \n",
              "2    에너지 생산실은 검은 대지를 관리하는 차원의 균열의 에너지를 다루는 곳입니다. 이...  [tensor(-0.5986)]   \n",
              "3    람바녹은 천계의 다른 모험가들과 달리 자신의 경험을 살려 무기를 다루는 법을 알려...   [tensor(5.9219)]   \n",
              "4    '머크 우드'는 노스피스의 북쪽으로, 황량한 사막과 끝없이 펼쳐진 바다가 끝없이 ...   [tensor(3.6680)]   \n",
              "5    '플레인 코스모필스'는 플레인에 거주하는 코스모핀이라는 존재입니다. 그는 다른 코...   [tensor(4.4531)]   \n",
              "6    헤블론의 주인은 헤블론 안에서만 살아가는 헤블론을 발견하고 헤블론에 머물고 싶어하...   [tensor(2.8164)]   \n",
              "7    네빌로 유를 찾기 위해서는 네빌로라는 인물의 행적을 알아야 합니다. 네빌로는 유르...   [tensor(1.3340)]   \n",
              "8    '칠흑'은 천계의 하늘을 방황하는 악귀들을 표현한 작품입니다. 이 작품은 선한 마...   [tensor(1.2354)]   \n",
              "9    최근에 모험가가 경험한 이야기로, 이야기 속에서 자신이 누구와 같이 모험을 떠나는...   [tensor(1.5322)]   \n",
              "10  世界는 하나의 眞眞급으로 구분되어 있으며, 그 외에도 몇몇 분류가 존재합니다. 예를...  [tensor(-0.3872)]   \n",
              "11   그렘린의 기원은 아라드에 존재했던 '그렘린'의 모습과 매우 흡사합니다. 그렘린이 ...   [tensor(3.0371)]   \n",
              "12   독 제장 비명을 보면 알 수 있듯이 비명은 자신을 방해하는 자에게 저주를 건 뒤,...   [tensor(1.7861)]   \n",
              "13   이 글에서는 검은 성전에 등장했던 반투족 기사의 이야기를 다루었습니다. 검은 성전...   [tensor(2.9766)]   \n",
              "14   이 비밀 기사 중에서는 비밀스러운 역할을 맡고 있습니다. 이들은 어떤 인물들인지 ...   [tensor(2.4453)]   \n",
              "15   던전에서만 볼 수 있는 거대하고 아름다운 생명체가 있어 이 생물과 함께 모험을 진...   [tensor(2.6895)]   \n",
              "\n",
              "      rewards (after)  \n",
              "0    [tensor(3.5957)]  \n",
              "1    [tensor(2.3184)]  \n",
              "2    [tensor(2.6523)]  \n",
              "3    [tensor(4.1758)]  \n",
              "4    [tensor(1.8340)]  \n",
              "5    [tensor(4.0039)]  \n",
              "6    [tensor(3.8770)]  \n",
              "7    [tensor(0.4771)]  \n",
              "8    [tensor(5.0312)]  \n",
              "9    [tensor(6.2031)]  \n",
              "10   [tensor(2.6973)]  \n",
              "11   [tensor(5.8398)]  \n",
              "12   [tensor(2.8945)]  \n",
              "13   [tensor(3.4746)]  \n",
              "14  [tensor(-0.0762)]  \n",
              "15   [tensor(2.2988)]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14241aed-6b48-46d1-8648-e25475c8f938\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>response (before)</th>\n",
              "      <th>response (after)</th>\n",
              "      <th>rewards (before)</th>\n",
              "      <th>rewards (after)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>타우킹 샤우타는 누구인가요?</td>\n",
              "      <td>타우킹 사도들은 샤우타를 타우로 부르고, 그들은 그를 타우킹이라 칭합니다. 이들은...</td>\n",
              "      <td>타우킹 타우는 타우타의 조상입니다. 원래는 불을 잘 다루었지만 그 능력이 점차 쇠...</td>\n",
              "      <td>[tensor(0.6245)]</td>\n",
              "      <td>[tensor(3.5957)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'오필리아 베이그란스'는 어떤 종교 집단의 신도인가요?</td>\n",
              "      <td>'오필리어 베이그란스는 루크를 따르는 자들 중 하나로, 현재는 교단에서 운영하는 ...</td>\n",
              "      <td>'오필리오 베이그란스'()는 황도군에 합류한 후에도 종교 단체에 남아 있었습니다....</td>\n",
              "      <td>[tensor(3.3848)]</td>\n",
              "      <td>[tensor(2.3184)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>에너지 생산실은 어떤 기능을 가지고 있나요?</td>\n",
              "      <td>에너지 생산실은 에너지 저장과 전송의 기능을 가지며, 각 에너지는 다양한 형태로 ...</td>\n",
              "      <td>에너지 생산실은 검은 대지를 관리하는 차원의 균열의 에너지를 다루는 곳입니다. 이...</td>\n",
              "      <td>[tensor(-0.5986)]</td>\n",
              "      <td>[tensor(2.6523)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'람바녹'은 어떤 사람이었나요?</td>\n",
              "      <td>람바녹은 그란플로리스의 주인으로, 검은 성전에 참가하여 모든 무기들을 파괴하고 많...</td>\n",
              "      <td>람바녹은 천계의 다른 모험가들과 달리 자신의 경험을 살려 무기를 다루는 법을 알려...</td>\n",
              "      <td>[tensor(5.9219)]</td>\n",
              "      <td>[tensor(4.1758)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'머크우드'는 어떤 곳인가요?</td>\n",
              "      <td>'머크 우드'는 마계를 상징하는 지역 중 하나로, 마계의 중심지인 마계 도시입니다...</td>\n",
              "      <td>'머크 우드'는 노스피스의 북쪽으로, 황량한 사막과 끝없이 펼쳐진 바다가 끝없이 ...</td>\n",
              "      <td>[tensor(3.6680)]</td>\n",
              "      <td>[tensor(1.8340)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>'플레인 : 코스모핀드'는 무엇인가요?</td>\n",
              "      <td>'플레인: 코스모필스'는 검은 마물의 후예이자 검은 마검사인 코스모 핀드를 지칭합...</td>\n",
              "      <td>'플레인 코스모필스'는 플레인에 거주하는 코스모핀이라는 존재입니다. 그는 다른 코...</td>\n",
              "      <td>[tensor(4.4531)]</td>\n",
              "      <td>[tensor(4.0039)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>헤블론 바실리움을 만든 주인은 누구인가요?</td>\n",
              "      <td>헤블론의 헤블론을 만든 주인입니다.  헤블롱은 자신을 위해서 죽은 주인을 기리기 ...</td>\n",
              "      <td>헤블론의 주인은 헤블론 안에서만 살아가는 헤블론을 발견하고 헤블론에 머물고 싶어하...</td>\n",
              "      <td>[tensor(2.8164)]</td>\n",
              "      <td>[tensor(3.8770)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>'네빌로 유르겐 행적'에 대해서 어떤 내용을 찾을 수 있나요?</td>\n",
              "      <td>본문에서는 네빌로 유를 겐트에 남은 마지막 귀족으로 언급하면서 그의 행적을 다루고...</td>\n",
              "      <td>네빌로 유를 찾기 위해서는 네빌로라는 인물의 행적을 알아야 합니다. 네빌로는 유르...</td>\n",
              "      <td>[tensor(1.3340)]</td>\n",
              "      <td>[tensor(0.4771)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>'칠흑의 송곳니'는 어떤 작품인가요?</td>\n",
              "      <td>'칠흑'은 선계 3대 아트의 하나인 \"칠흑의 분노\"를 주제로 한 작품입니다. 이 ...</td>\n",
              "      <td>'칠흑'은 천계의 하늘을 방황하는 악귀들을 표현한 작품입니다. 이 작품은 선한 마...</td>\n",
              "      <td>[tensor(1.2354)]</td>\n",
              "      <td>[tensor(5.0312)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>어떤 내용에 대한 요약을 진행하였습니까?</td>\n",
              "      <td>선민의식이라는 소재를 중심으로 하여, 이는 그의 작품 전반에 흐르는 주요 특징 ...</td>\n",
              "      <td>최근에 모험가가 경험한 이야기로, 이야기 속에서 자신이 누구와 같이 모험을 떠나는...</td>\n",
              "      <td>[tensor(1.5322)]</td>\n",
              "      <td>[tensor(6.2031)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>세계는 어떻게 구분되나요?</td>\n",
              "      <td>...본문에는 자세한 설명이 제공되지 않았습니다. 제가 해석한 내용이므로 추가적인 ...</td>\n",
              "      <td>世界는 하나의 眞眞급으로 구분되어 있으며, 그 외에도 몇몇 분류가 존재합니다. 예를...</td>\n",
              "      <td>[tensor(-0.3872)]</td>\n",
              "      <td>[tensor(2.6973)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>그렘린은 어떤 종족인가요?</td>\n",
              "      <td>그렘린들은 이계의 신수 중 하나입니다. 그들은 종족 특성상 강한 힘을 바탕으로 생...</td>\n",
              "      <td>그렘린의 기원은 아라드에 존재했던 '그렘린'의 모습과 매우 흡사합니다. 그렘린이 ...</td>\n",
              "      <td>[tensor(3.0371)]</td>\n",
              "      <td>[tensor(5.8398)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>'독 제장 비명'에 대한 내용은 무엇인가요?</td>\n",
              "      <td>대자연 속에서 피를 흘리며 홀로 죽음을 맞이하는 한 여인의 모습과 그녀의 울음소리...</td>\n",
              "      <td>독 제장 비명을 보면 알 수 있듯이 비명은 자신을 방해하는 자에게 저주를 건 뒤,...</td>\n",
              "      <td>[tensor(1.7861)]</td>\n",
              "      <td>[tensor(2.8945)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>'데스페라도'에 대한 내용을 간단히 설명해주세요.</td>\n",
              "      <td>이 검에 깃든 힘은 신과의 약속을 지키기 위해 사용되고 있습니다. 이 검은 죽음의...</td>\n",
              "      <td>이 글에서는 검은 성전에 등장했던 반투족 기사의 이야기를 다루었습니다. 검은 성전...</td>\n",
              "      <td>[tensor(2.9766)]</td>\n",
              "      <td>[tensor(3.4746)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>이 비밀 기사들은 어떤 역할을 수행하고 있나요?</td>\n",
              "      <td>...시로코의 예언의 빛과 함께 어둠의 기운을 사용하여 어둠의 기사들이 비밀을 지키...</td>\n",
              "      <td>이 비밀 기사 중에서는 비밀스러운 역할을 맡고 있습니다. 이들은 어떤 인물들인지 ...</td>\n",
              "      <td>[tensor(2.4453)]</td>\n",
              "      <td>[tensor(-0.0762)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>덴드로이드의 정글은 어떤 내용을 다루고 있나요?</td>\n",
              "      <td>정글에는 다양한 종류의 식물과 곤충들이 서식하고 있습니다. 덴드로이드들은 정글을 ...</td>\n",
              "      <td>던전에서만 볼 수 있는 거대하고 아름다운 생명체가 있어 이 생물과 함께 모험을 진...</td>\n",
              "      <td>[tensor(2.6895)]</td>\n",
              "      <td>[tensor(2.2988)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14241aed-6b48-46d1-8648-e25475c8f938')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14241aed-6b48-46d1-8648-e25475c8f938 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14241aed-6b48-46d1-8648-e25475c8f938');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f616edfa-e856-4010-886f-c6cb6ee74e9c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f616edfa-e856-4010-886f-c6cb6ee74e9c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f616edfa-e856-4010-886f-c6cb6ee74e9c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8048857e-e8a8-407d-b9eb-4ac86a7f0cea\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8048857e-e8a8-407d-b9eb-4ac86a7f0cea button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#### get a batch from the dataset\n",
        "bs = 16\n",
        "game_data = dict()\n",
        "dataset.set_format(\"pandas\")\n",
        "df_batch = dataset[:].sample(bs)\n",
        "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
        "query_tensors = df_batch[\"input_ids\"].tolist()\n",
        "\n",
        "\n",
        "response_tensors_ref, response_tensors = [], []\n",
        "\n",
        "#### get response from PPO_SFT, ref_SFT\n",
        "for i in tqdm(range(bs)):\n",
        "    output = gen(make_input(game_data['query'][i]), model_ref)\n",
        "    response_tensors_ref.append(output)\n",
        "\n",
        "    output = gen(make_input(game_data['query'][i]), model)\n",
        "    response_tensors.append(output)\n",
        "\n",
        "\n",
        "#### decode responses\n",
        "game_data[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
        "game_data[\"response (after)\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
        "\n",
        "#### sentiment analysis of query/response pairs before/after\n",
        "tmp = []\n",
        "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
        "for txt in texts:\n",
        "  tmp.append(inference_RM(rm_model, txt))\n",
        "game_data[\"rewards (before)\"] = tmp\n",
        "\n",
        "tmp =[]\n",
        "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
        "for txt in texts:\n",
        "  tmp.append(inference_RM(rm_model, txt))\n",
        "game_data[\"rewards (after)\"] = tmp\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# store results in a dataframe\n",
        "df_results = pd.DataFrame(game_data)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in df_results[:5].iterrows():\n",
        "  print(\"Query : \", row[\"query\"])\n",
        "  print(\"Response (before) : \", row[\"response (before)\"])\n",
        "  print(\"Response (after) : \", row[\"response (after)\"])\n",
        "  print(\"Rewards (before)/(after) : \", row[\"rewards (before)\"],'/',row[\"rewards (after)\"])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqsybSLHAsRV",
        "outputId": "43a6a2f8-13ba-41f1-dd64-877685100aef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query :  타우킹 샤우타는 누구인가요?\n",
            "Response (before) :   타우킹 사도들은 샤우타를 타우로 부르고, 그들은 그를 타우킹이라 칭합니다. 이들은 샤우드의 우두머리로서 역할을 수행합니다. 또한, 타우킹은 타우라는 이름의 사도에 의해 소환되는 존재로서 그의 권능을 통해 자신의 권능으로 다른 존재를 제어하고 지배할 수 있습니다. 그들은 샤우트의 힘에 의해 타우라는 힘을 부여받고 그의 능력을 사용하여 타우킹으로 불리며, 타우의 권능에 의해 다른 개체들을 지배할 수는 없지만\n",
            "Response (after) :   타우킹 타우는 타우타의 조상입니다. 원래는 불을 잘 다루었지만 그 능력이 점차 쇠퇴해지면서 현재는 타우킹이 되었습니다. 이들은 주로 숲에서 활동하며 타우타와 같이 나무를 자릅니다. 타우타는 나무를 잘 다루며 숲을 지키기 위해 노력하고 있습니다.  타우타가 자신의 모습을 본떠 만들어졌다고 말하는 이가 있지만 타우타 자체는 타우타나 타우타를 본떠 만들지 않았습니다. 하지만 타우타에 대한 전설이나 이야기들이 전해\n",
            "Rewards (before)/(after) :  tensor([0.6245]) / tensor([3.5957])\n",
            "\n",
            "Query :  '오필리아 베이그란스'는 어떤 종교 집단의 신도인가요?\n",
            "Response (before) :   '오필리어 베이그란스는 루크를 따르는 자들 중 하나로, 현재는 교단에서 운영하는 특수 조직의 일원입니다. 그녀는 루크의 특별한 능력을 받았으며, 이 능력으로 자신들을 이끌어 루크의 제국을 지키는 역할을 하고 있습니다.' 오필리어 베이 그란스는 종교 집단의 정신적인 지주로서 그의 능력을 믿고 따르는 신도입니다. 그녀가 자신들을 지키기 위해 수호신의 힘을 빌린다는 이야기를 들은 적이 있습니다. 현재는 교단 내부에서 자신들이 맡고 있는\n",
            "Response (after) :   '오필리오 베이그란스'()는 황도군에 합류한 후에도 종교 단체에 남아 있었습니다. 그러나 현재는 신도들의 반발로 신도들과 함께 집단 자살을 하는 것으로 알려졌습니다. 그 후 오필리아 베이 그란스는 자신의 배를 타고 도주하며 종교적인 힘을 이용해 집단을 결속했습니다. 이후 신도들은 이 종교 집단에 다시 합류할 것을 희망하고 있습니다. 하지만 현재는 신도 수가 매우 적어 다시 합류할 확률은 매우 적은 상황입니다. 그녀는 자신이 속한 종교에 대해 어떤 신념을 가지고\n",
            "Rewards (before)/(after) :  tensor([3.3848]) / tensor([2.3184])\n",
            "\n",
            "Query :  에너지 생산실은 어떤 기능을 가지고 있나요?\n",
            "Response (before) :   에너지 생산실은 에너지 저장과 전송의 기능을 가지며, 각 에너지는 다양한 형태로 사용됩니다. 에너지 저장을 위해서는 거대한 공간을 사용하며, 공간의 에너지는 다양하게 사용됩니다. 전송을 위해서는 공간을 이용한 전자기기들을 사용할 수 있으며, 이 기능은 다른 에너지 시스템과 다른 에너지 저장 및 전송 시스템이 갖고 있는 능력입니다. 이와 관련된 기능은 에너지 생산실이 갖는 고유한 기능입니다.  에너지 저장실에 대해서는 자세한 정보가 제공되지 않았습니다. 최근까지는 에너지 저장실의 기능이\n",
            "Response (after) :   에너지 생산실은 검은 대지를 관리하는 차원의 균열의 에너지를 다루는 곳입니다. 이 시설은 검은 대지와 차원의 에너지를 관리하고 연구하는 데 사용됩니다. 이곳에서는 차원의 에너지로 에너지의 흐름을 조종하고, 그로 인해 검은 대지에 새로운 에너지가 모이게 됩니다. 시설은 거대한 에너지와 검은 대지의 에너지를 결합하고 관리하여 차원의 균열에서 흘러들어오는 에너지를 효과적으로 통제할 수 있습니다. 이 시설에 대한 자세한 설명은 본문에 제공되지 않았습니다.  검은 대지가 사라지면서 나타난\n",
            "Rewards (before)/(after) :  tensor([-0.5986]) / tensor([2.6523])\n",
            "\n",
            "Query :  '람바녹'은 어떤 사람이었나요?\n",
            "Response (before) :   람바녹은 그란플로리스의 주인으로, 검은 성전에 참가하여 모든 무기들을 파괴하고 많은 희생을 치른 전설적인 인물입니다. 검은 성전이 끝난 후, 검은 교단에 포로로 잡혀 검은 성수로 끌려갔습니다. 그의 몸에는 많은 무기들과 무기들과 같이 죽은 검은 성혈을 가지고 있었습니다. 람바녹이 남긴 검은 성수는 무기에 대한 힘을 가진 사람이며, 이 무기들로 많은 사람들을 살육한 것으로 전해집니다. 전설에 따르면 그의\n",
            "Response (after) :   람바녹은 천계의 다른 모험가들과 달리 자신의 경험을 살려 무기를 다루는 법을 알려주고, 무기상에게 장비와 재료들을 구입하는 방법을 알려주는 모험가였습니다. 그래서 자신의 모험가 생활을 자랑하기 보다는 도움을 받은 모험가들을 생각하며 자신의 무기도 아낌없이 나누었다고 합니다. 그래서 그의 이름이 널리 알려져있는 것 같습니다. 그가 무기를 나누었다는 사실은 모험가 생활에서 중요한 위치를 차지하는 것으로 보입니다. 그의 삶은 모험가로서 큰 성장\n",
            "Rewards (before)/(after) :  tensor([5.9219]) / tensor([4.1758])\n",
            "\n",
            "Query :  '머크우드'는 어떤 곳인가요?\n",
            "Response (before) :   '머크 우드'는 마계를 상징하는 지역 중 하나로, 마계의 중심지인 마계 도시입니다. 이곳은 거대한 숲과 계곡이 있어 모험가들의 눈을 사로 잡는 곳이기도 합니다. 현재는 '머크 타운'이라는 이름으로 마계 도시로 자리 잡고 있습니다. 모험가들은 이곳에서 모험을 시작해 마계를 정복하고 마계에 뿌리를 내리려는 야망을 가지고 있습니다..  한편, '머크타운'에서는 모험가들에게 필요한 것들을 제공하기 위해 다양한 서비스를\n",
            "Response (after) :   '머크 우드'는 노스피스의 북쪽으로, 황량한 사막과 끝없이 펼쳐진 바다가 끝없이 펼쳐지는 곳입니다. 이곳은 모험가들의 성지이며, 신비한 고대 마법진들이 존재하는 곳입니다.\" 머크우드에는 오래된 마법진이 있는데, 그곳에 들어가면 다양한 마법진을 만나볼 수 있습니다.\"라고 '머크위드'에 대한 자세한 정보가 제공됩니다. 머크우드는 오래된 고대 마법진이 존재하는 장소로 알려져 있습니다. '머크 위드'에서는 머크우드의 마법진을 이용해 다양한 마법을\n",
            "Rewards (before)/(after) :  tensor([3.6680]) / tensor([1.8340])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c-RPI9uhVyc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "59321792-07c7-43e9-bc35-2008c4c5e367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "rewards (before)    2.307434\n",
              "rewards (after)     3.206085\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "median:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "rewards (before)    2.567383\n",
              "rewards (after)     3.184570\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"mean:\")\n",
        "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\n",
        "print()\n",
        "print(\"median:\")\n",
        "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScUkCr3rVy9P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGaBWzdVz32f"
      },
      "source": [
        "## Train 12.8b Model base with A100 one step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zuju7ukNLTv5",
        "outputId": "313e4e63-706c-4afe-8665-0b7f9d8fd9e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'objective/kl': 56.351043701171875,\n",
              " 'objective/kl_dist': 56.351043701171875,\n",
              " 'objective/logprobs': array([[-1.45925608e+01, -2.46456456e+00, -1.60551977e+00,\n",
              "         -5.56262493e+00, -3.77504015e+00, -1.73158407e+00,\n",
              "         -5.53011179e+00, -9.62687874e+00, -2.19370961e-01,\n",
              "         -3.63981158e-01, -7.25596130e-01, -5.28046417e+00,\n",
              "         -7.88754225e-02, -4.61143218e-02, -8.07286054e-02,\n",
              "         -8.75985846e-02, -1.96038413e+00, -3.66744590e+00,\n",
              "         -1.24913186e-01, -1.84856510e+00, -9.54421908e-02,\n",
              "         -4.05263805e+00, -2.81907648e-01, -2.47410852e-02,\n",
              "         -5.21565497e-01, -2.53694940e+00, -5.41553088e-03,\n",
              "         -4.58302610e-02, -9.91374731e-01, -7.24837780e-01,\n",
              "         -2.68632722e+00, -2.54865885e-01, -5.36051532e-03,\n",
              "         -2.25284767e+00, -1.47872102e+00, -1.14727473e+00,\n",
              "         -7.67057896e-01, -1.82066262e+00, -5.62259138e-01,\n",
              "         -2.25619271e-01, -5.44962406e-01, -1.39080846e+00,\n",
              "         -3.23882282e-01, -2.24916553e+00, -1.32182491e+00,\n",
              "         -9.93629098e-01, -4.68611813e+00, -3.04281618e-02,\n",
              "         -8.23234379e-01, -2.33762550e+00, -2.30577022e-01,\n",
              "         -1.61049104e+00, -7.84237146e-01, -3.05025196e+00,\n",
              "         -5.93527332e-02, -1.52324748e+00, -1.06254555e-02,\n",
              "         -2.26629376e+00, -1.40662745e-01, -1.28895903e+00,\n",
              "         -2.40231618e-01, -2.18018460e+00, -1.13473982e-02,\n",
              "         -5.40269613e-01, -1.00019026e+00, -1.24755788e+00,\n",
              "         -2.03874987e-02, -1.06043424e-02, -7.20357001e-01,\n",
              "         -4.52090472e-01, -2.39852619e+00, -5.93022585e-01,\n",
              "         -5.27499080e-01, -2.23910972e-01, -2.71124864e+00,\n",
              "         -3.79366404e-03, -1.91742197e-01, -8.52734089e-01,\n",
              "         -7.86467433e-01, -1.15137041e+00, -5.29622197e-01,\n",
              "         -6.50708914e-01, -1.30863667e+00, -1.03315055e-01,\n",
              "         -2.87212777e+00, -2.12249793e-02, -1.91612134e-03,\n",
              "         -5.86530603e-02, -1.12480344e-02, -2.45415211e+00,\n",
              "         -4.27736668e-03, -4.00953367e-02, -2.51861405e+00,\n",
              "         -1.09847355e+00, -1.94655490e+00, -9.07179993e-03,\n",
              "         -3.45909119e+00, -7.21546054e-01, -2.00253081e+00,\n",
              "         -6.07948482e-01, -1.53975451e+00, -2.27959245e-01,\n",
              "         -4.57039522e-03, -5.77997998e-04, -8.36447775e-01,\n",
              "         -1.22136183e-01, -2.57420540e+00, -1.01299454e-02,\n",
              "         -3.17826986e+00, -1.12207815e-01, -4.23920363e-01,\n",
              "         -2.26992607e+00, -6.26204133e-01, -2.48343855e-01,\n",
              "         -3.56254071e-01, -2.03394604e+00, -1.34620845e+00,\n",
              "         -1.64137393e-01, -6.15493417e-01, -2.87452750e-02,\n",
              "         -1.04051316e-03, -3.64588022e+00, -2.60915346e-02,\n",
              "         -4.13721502e-02, -1.07313683e-02, -2.85962057e+00,\n",
              "         -7.73569405e-01, -2.47229195e+00, -2.85431325e-01,\n",
              "         -1.12029922e+00, -2.02126116e-01, -3.42289448e+00,\n",
              "         -8.48734126e-05, -1.98546684e+00, -4.70012009e-01]], dtype=float32),\n",
              " 'objective/ref_logprobs': array([[-7.8721471e+00, -4.3985987e+00, -1.6446271e+00, -6.4243174e+00,\n",
              "         -3.5772133e+00, -1.6674447e+00, -5.1510592e+00, -8.8367500e+00,\n",
              "         -3.4220777e-02, -9.5918792e-01, -9.2323864e-01, -7.5541835e+00,\n",
              "         -8.4056383e-01, -1.1349727e-01, -3.1371408e+00, -5.9444737e-02,\n",
              "         -3.2537351e+00, -7.4459672e+00, -4.0544119e+00, -6.4193449e+00,\n",
              "         -1.3864851e-01, -6.2631865e+00, -4.4615817e+00, -9.1516840e-01,\n",
              "         -6.1203742e-01, -7.1573796e+00, -6.8069977e-01, -1.9265227e-01,\n",
              "         -3.2123559e+00, -7.9634905e-01, -4.8171186e+00, -1.9299364e+00,\n",
              "         -1.0825359e-02, -1.9295859e+00, -1.5638745e+00, -1.2693909e+00,\n",
              "         -8.1826305e-01, -1.0270023e+00, -8.6995959e-01, -5.0646472e-01,\n",
              "         -8.0691874e-01, -2.5402322e+00, -5.0913990e-02, -3.2433877e+00,\n",
              "         -2.4393935e+00, -1.2724628e+00, -3.7457368e+00, -2.2960870e-02,\n",
              "         -1.0888963e+00, -2.4570055e+00, -4.4581604e-01, -1.3235883e+00,\n",
              "         -1.2786230e+00, -4.3127532e+00, -9.8987974e-02, -1.4265580e+00,\n",
              "         -6.1549481e-02, -2.2436445e+00, -4.3406814e-01, -1.4061303e+00,\n",
              "         -4.0018037e-01, -2.8933284e+00, -1.9668080e-02, -5.3968143e-01,\n",
              "         -8.9277577e-01, -1.1035072e+00, -2.9458657e-02, -2.6014067e-02,\n",
              "         -7.7772510e-01, -5.3769016e-01, -4.0610008e+00, -3.5400319e-01,\n",
              "         -9.0045786e-01, -3.0732104e-01, -3.4634964e+00, -5.3159310e-03,\n",
              "         -1.0343621e+00, -8.6526263e-01, -9.1961676e-01, -2.5785832e+00,\n",
              "         -5.5447406e-01, -3.2040200e-01, -1.7926378e+00, -1.4028050e-01,\n",
              "         -2.1569004e+00, -1.6637623e-02, -8.2331784e-03, -6.2303025e-02,\n",
              "         -1.5266004e-02, -2.6287160e+00, -2.2391027e-03, -1.4423810e-01,\n",
              "         -2.4081612e+00, -1.2298775e+00, -1.8956168e+00, -9.7707836e-03,\n",
              "         -4.7297506e+00, -9.9195278e-01, -2.3755116e+00, -6.6493279e-01,\n",
              "         -1.7539519e+00, -3.0856735e-01, -4.8920461e-03, -2.7328308e-03,\n",
              "         -7.4947703e-01, -1.6319166e-01, -2.5254543e+00, -1.1945263e-02,\n",
              "         -3.2244630e+00, -1.4276098e-01, -5.6927454e-01, -2.0811980e+00,\n",
              "         -1.1670961e+00, -4.2358607e-01, -2.7123085e-01, -2.5419421e+00,\n",
              "         -2.3633716e+00, -1.7475495e-01, -7.8623033e-01, -3.4242321e-02,\n",
              "         -4.4868509e-03, -3.6698117e+00, -4.0067736e-02, -8.0600485e-02,\n",
              "         -1.8344037e-02, -3.3044009e+00, -8.7986338e-01, -2.0392029e+00,\n",
              "         -8.0921084e-01, -9.8174387e-01, -2.8825656e-01, -3.7879992e+00,\n",
              "         -2.9023251e-04, -3.4620433e+00, -9.0189493e-01]], dtype=float32),\n",
              " 'objective/kl_coef': 0.2,\n",
              " 'objective/entropy': 140.5786895751953,\n",
              " 'ppo/mean_non_score_reward': -0.08804849535226822,\n",
              " 'ppo/mean_scores': 3.4700000286102295,\n",
              " 'ppo/std_scores': nan,\n",
              " 'tokens/queries_len_mean': 8.0,\n",
              " 'tokens/queries_len_std': nan,\n",
              " 'tokens/queries_dist': 8.0,\n",
              " 'tokens/responses_len_mean': 128.0,\n",
              " 'tokens/responses_len_std': nan,\n",
              " 'tokens/responses_dist': 128.0,\n",
              " 'ppo/loss/policy': -1.4901161193847656e-08,\n",
              " 'ppo/loss/value': 3.203397512435913,\n",
              " 'ppo/loss/total': 0.32033973932266235,\n",
              " 'ppo/policy/entropy': 1.9164319038391113,\n",
              " 'ppo/policy/approxkl': 0.0,\n",
              " 'ppo/policy/policykl': 0.0,\n",
              " 'ppo/policy/clipfrac': 0.0,\n",
              " 'ppo/policy/advantages': array([-0.6834126 , -0.73457956, -0.7884395 , -0.8451342 , -0.9048128 ,\n",
              "        -0.9676324 , -1.0337584 , -2.2602038 , -3.0123699 , -1.7789301 ,\n",
              "        -1.7156492 , -1.5791692 , -2.457174  , -2.4127028 , -1.4310954 ,\n",
              "        -1.4361448 , -1.4078056 , -1.3540527 , -2.321977  , -1.2995957 ,\n",
              "        -1.0884451 , -1.1047703 , -1.3291004 , -1.2335063 , -0.6760565 ,\n",
              "        -0.5457796 , -0.7707971 , -0.43617374, -0.4704246 , -0.14981966,\n",
              "         0.16081564, -1.4918882 , -0.19294162, -0.16122437,  0.11282659,\n",
              "         0.69912916,  0.4818174 ,  0.8723967 , -0.8075286 , -0.7689785 ,\n",
              "         0.31313217, -0.52049595, -1.1161563 , -0.788861  ,  0.12965684,\n",
              "         0.4450407 ,  0.5810419 , -1.9802445 , -0.42030373,  0.596024  ,\n",
              "         0.18694185,  0.51967937,  0.01273927,  0.3769523 ,  0.1180895 ,\n",
              "        -0.14675243, -1.0373421 , -0.59727615,  0.40427387,  0.26393646,\n",
              "         0.47038403,  0.29301992, -0.92606825,  0.60634726,  0.22342092,\n",
              "         0.24025348, -0.32906705, -0.12199976, -0.24734503,  0.27430552,\n",
              "         0.20548746,  0.4270237 ,  0.01716162, -0.26277375,  0.52877784,\n",
              "        -0.8262882 ,  0.72514313,  0.29944232, -0.1139047 ,  0.815132  ,\n",
              "         0.2840169 , -0.05332648,  0.7102787 ,  0.78456473,  0.03869656,\n",
              "         0.14101674, -0.15803565,  0.121534  , -1.1696572 , -0.6986787 ,\n",
              "        -1.2983725 ,  0.12721369,  0.4004099 ,  0.56995845,  0.6761791 ,\n",
              "        -0.6636517 ,  1.1544472 ,  0.91285217,  1.2266113 ,  0.99664533,\n",
              "         0.597013  , -0.38954479,  0.32965925, -0.07534879,  0.21558928,\n",
              "         0.8463347 ,  0.90751916, -0.54892707,  1.4719179 ,  0.5394606 ,\n",
              "         0.34823465,  1.004326  ,  1.3150425 ,  0.72014856,  0.5309186 ,\n",
              "         0.9184475 ,  1.2896614 ,  0.7819023 ,  0.7639344 ,  0.79495126,\n",
              "         0.46918434,  0.9831348 ,  1.0197425 ,  0.7307615 , -0.31204438,\n",
              "         0.07007359,  1.4241182 ,  1.5578022 ,  1.4815196 ,  1.4347202 ,\n",
              "         1.6072297 ,  1.8355749 ,  0.73452413,  2.384758  ,  1.8437495 ,\n",
              "        -0.6834126 , -0.73457956, -0.7884395 , -0.8451342 , -0.9048128 ,\n",
              "        -0.9676324 , -1.0337584 , -2.2602038 , -3.0123699 , -1.7789301 ,\n",
              "        -1.7156492 , -1.5791692 , -2.457174  , -2.4127028 , -1.4310954 ,\n",
              "        -1.4361448 , -1.4078056 , -1.3540527 , -2.321977  , -1.2995957 ,\n",
              "        -1.0884451 , -1.1047703 , -1.3291004 , -1.2335063 , -0.6760565 ,\n",
              "        -0.5457796 , -0.7707971 , -0.43617374, -0.4704246 , -0.14981966,\n",
              "         0.16081564, -1.4918882 , -0.19294162, -0.16122437,  0.11282659,\n",
              "         0.69912916,  0.4818174 ,  0.8723967 , -0.8075286 , -0.7689785 ,\n",
              "         0.31313217, -0.52049595, -1.1161563 , -0.788861  ,  0.12965684,\n",
              "         0.4450407 ,  0.5810419 , -1.9802445 , -0.42030373,  0.596024  ,\n",
              "         0.18694185,  0.51967937,  0.01273927,  0.3769523 ,  0.1180895 ,\n",
              "        -0.14675243, -1.0373421 , -0.59727615,  0.40427387,  0.26393646,\n",
              "         0.47038403,  0.29301992, -0.92606825,  0.60634726,  0.22342092,\n",
              "         0.24025348, -0.32906705, -0.12199976, -0.24734503,  0.27430552,\n",
              "         0.20548746,  0.4270237 ,  0.01716162, -0.26277375,  0.52877784,\n",
              "        -0.8262882 ,  0.72514313,  0.29944232, -0.1139047 ,  0.815132  ,\n",
              "         0.2840169 , -0.05332648,  0.7102787 ,  0.78456473,  0.03869656,\n",
              "         0.14101674, -0.15803565,  0.121534  , -1.1696572 , -0.6986787 ,\n",
              "        -1.2983725 ,  0.12721369,  0.4004099 ,  0.56995845,  0.6761791 ,\n",
              "        -0.6636517 ,  1.1544472 ,  0.91285217,  1.2266113 ,  0.99664533,\n",
              "         0.597013  , -0.38954479,  0.32965925, -0.07534879,  0.21558928,\n",
              "         0.8463347 ,  0.90751916, -0.54892707,  1.4719179 ,  0.5394606 ,\n",
              "         0.34823465,  1.004326  ,  1.3150425 ,  0.72014856,  0.5309186 ,\n",
              "         0.9184475 ,  1.2896614 ,  0.7819023 ,  0.7639344 ,  0.79495126,\n",
              "         0.46918434,  0.9831348 ,  1.0197425 ,  0.7307615 , -0.31204438,\n",
              "         0.07007359,  1.4241182 ,  1.5578022 ,  1.4815196 ,  1.4347202 ,\n",
              "         1.6072297 ,  1.8355749 ,  0.73452413,  2.384758  ,  1.8437495 ,\n",
              "        -0.6834126 , -0.73457956, -0.7884395 , -0.8451342 , -0.9048128 ,\n",
              "        -0.9676324 , -1.0337584 , -2.2602038 , -3.0123699 , -1.7789301 ,\n",
              "        -1.7156492 , -1.5791692 , -2.457174  , -2.4127028 , -1.4310954 ,\n",
              "        -1.4361448 , -1.4078056 , -1.3540527 , -2.321977  , -1.2995957 ,\n",
              "        -1.0884451 , -1.1047703 , -1.3291004 , -1.2335063 , -0.6760565 ,\n",
              "        -0.5457796 , -0.7707971 , -0.43617374, -0.4704246 , -0.14981966,\n",
              "         0.16081564, -1.4918882 , -0.19294162, -0.16122437,  0.11282659,\n",
              "         0.69912916,  0.4818174 ,  0.8723967 , -0.8075286 , -0.7689785 ,\n",
              "         0.31313217, -0.52049595, -1.1161563 , -0.788861  ,  0.12965684,\n",
              "         0.4450407 ,  0.5810419 , -1.9802445 , -0.42030373,  0.596024  ,\n",
              "         0.18694185,  0.51967937,  0.01273927,  0.3769523 ,  0.1180895 ,\n",
              "        -0.14675243, -1.0373421 , -0.59727615,  0.40427387,  0.26393646,\n",
              "         0.47038403,  0.29301992, -0.92606825,  0.60634726,  0.22342092,\n",
              "         0.24025348, -0.32906705, -0.12199976, -0.24734503,  0.27430552,\n",
              "         0.20548746,  0.4270237 ,  0.01716162, -0.26277375,  0.52877784,\n",
              "        -0.8262882 ,  0.72514313,  0.29944232, -0.1139047 ,  0.815132  ,\n",
              "         0.2840169 , -0.05332648,  0.7102787 ,  0.78456473,  0.03869656,\n",
              "         0.14101674, -0.15803565,  0.121534  , -1.1696572 , -0.6986787 ,\n",
              "        -1.2983725 ,  0.12721369,  0.4004099 ,  0.56995845,  0.6761791 ,\n",
              "        -0.6636517 ,  1.1544472 ,  0.91285217,  1.2266113 ,  0.99664533,\n",
              "         0.597013  , -0.38954479,  0.32965925, -0.07534879,  0.21558928,\n",
              "         0.8463347 ,  0.90751916, -0.54892707,  1.4719179 ,  0.5394606 ,\n",
              "         0.34823465,  1.004326  ,  1.3150425 ,  0.72014856,  0.5309186 ,\n",
              "         0.9184475 ,  1.2896614 ,  0.7819023 ,  0.7639344 ,  0.79495126,\n",
              "         0.46918434,  0.9831348 ,  1.0197425 ,  0.7307615 , -0.31204438,\n",
              "         0.07007359,  1.4241182 ,  1.5578022 ,  1.4815196 ,  1.4347202 ,\n",
              "         1.6072297 ,  1.8355749 ,  0.73452413,  2.384758  ,  1.8437495 ,\n",
              "        -0.6834126 , -0.73457956, -0.7884395 , -0.8451342 , -0.9048128 ,\n",
              "        -0.9676324 , -1.0337584 , -2.2602038 , -3.0123699 , -1.7789301 ,\n",
              "        -1.7156492 , -1.5791692 , -2.457174  , -2.4127028 , -1.4310954 ,\n",
              "        -1.4361448 , -1.4078056 , -1.3540527 , -2.321977  , -1.2995957 ,\n",
              "        -1.0884451 , -1.1047703 , -1.3291004 , -1.2335063 , -0.6760565 ,\n",
              "        -0.5457796 , -0.7707971 , -0.43617374, -0.4704246 , -0.14981966,\n",
              "         0.16081564, -1.4918882 , -0.19294162, -0.16122437,  0.11282659,\n",
              "         0.69912916,  0.4818174 ,  0.8723967 , -0.8075286 , -0.7689785 ,\n",
              "         0.31313217, -0.52049595, -1.1161563 , -0.788861  ,  0.12965684,\n",
              "         0.4450407 ,  0.5810419 , -1.9802445 , -0.42030373,  0.596024  ,\n",
              "         0.18694185,  0.51967937,  0.01273927,  0.3769523 ,  0.1180895 ,\n",
              "        -0.14675243, -1.0373421 , -0.59727615,  0.40427387,  0.26393646,\n",
              "         0.47038403,  0.29301992, -0.92606825,  0.60634726,  0.22342092,\n",
              "         0.24025348, -0.32906705, -0.12199976, -0.24734503,  0.27430552,\n",
              "         0.20548746,  0.4270237 ,  0.01716162, -0.26277375,  0.52877784,\n",
              "        -0.8262882 ,  0.72514313,  0.29944232, -0.1139047 ,  0.815132  ,\n",
              "         0.2840169 , -0.05332648,  0.7102787 ,  0.78456473,  0.03869656,\n",
              "         0.14101674, -0.15803565,  0.121534  , -1.1696572 , -0.6986787 ,\n",
              "        -1.2983725 ,  0.12721369,  0.4004099 ,  0.56995845,  0.6761791 ,\n",
              "        -0.6636517 ,  1.1544472 ,  0.91285217,  1.2266113 ,  0.99664533,\n",
              "         0.597013  , -0.38954479,  0.32965925, -0.07534879,  0.21558928,\n",
              "         0.8463347 ,  0.90751916, -0.54892707,  1.4719179 ,  0.5394606 ,\n",
              "         0.34823465,  1.004326  ,  1.3150425 ,  0.72014856,  0.5309186 ,\n",
              "         0.9184475 ,  1.2896614 ,  0.7819023 ,  0.7639344 ,  0.79495126,\n",
              "         0.46918434,  0.9831348 ,  1.0197425 ,  0.7307615 , -0.31204438,\n",
              "         0.07007359,  1.4241182 ,  1.5578022 ,  1.4815196 ,  1.4347202 ,\n",
              "         1.6072297 ,  1.8355749 ,  0.73452413,  2.384758  ,  1.8437495 ],\n",
              "       dtype=float32),\n",
              " 'ppo/policy/advantages_mean': 1.4901161193847656e-08,\n",
              " 'ppo/policy/ratio': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
              " 'ppo/returns/mean': -0.7310409545898438,\n",
              " 'ppo/returns/var': 2.8230972290039062,\n",
              " 'ppo/val/vpred': -0.045290131121873856,\n",
              " 'ppo/val/error': 6.406795024871826,\n",
              " 'ppo/val/clipfrac': 0.0,\n",
              " 'ppo/val/mean': -0.02063962072134018,\n",
              " 'ppo/val/var': 2.090665578842163,\n",
              " 'ppo/val/var_explained': -1.2694206237792969,\n",
              " 'ppo/learning_rate': 1e-05,\n",
              " 'time/ppo/forward_pass': 1.7308757305145264,\n",
              " 'time/ppo/compute_rewards': 0.07280516624450684,\n",
              " 'time/ppo/compute_advantages': 0.20197606086730957,\n",
              " 'time/ppo/optimize_step': 1.8437983989715576,\n",
              " 'time/ppo/calc_stats': 0.04517507553100586,\n",
              " 'time/ppo/total': 3.895861864089966}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_txt = \"아라드 대륙에 대해서 설명해줘\"\n",
        "query_encode = make_input(query_txt)\n",
        "query_tensors = tokenizer.encode(query_txt, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "response = '아라드 대륙은 벨 마이어 공국, 반투국, 수쥬국, 흑요정 왕국, 데 로스 제국 등 여러 국가가 존재하는 대륙입니다. 이 대륙은 아라드 대륙이라는 이름으로 알려져 있습니다. 이 대륙에는 다양한 종족들이 살고 있으며, 모험가들은 다양한 종족들과 교류하며 모험을 즐길 수 있습니다. 아라드 대륙에서는 다양한 문화와 역사를 경험할 수 있으며, 다양한 사람들과의 교류를 통해 새로운 경험을 할 수 있을 것입니다. 또한, 이 대륙에서는 수많은 유적과'\n",
        "response_tensors = tokenizer.encode(response, return_tensors=\"pt\")\n",
        "\n",
        "rewards = [torch.tensor(3.47)]\n",
        "\n",
        "ppo_trainer.step([query_tensors[0]], [response_tensors[0]], rewards)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "tikow03TKmT6",
        "ZGaBWzdVz32f"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10946261c9e24c65a9d27a0b008a8880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15e939b0a0e64f9096642e93aeccd0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2eeb2026b444bdaf964e10286f1f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38be7f7a4d754b368de499ec2039b7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918f913851b645748089ae538e0aaccd",
            "max": 35964,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10946261c9e24c65a9d27a0b008a8880",
            "value": 35964
          }
        },
        "41bc288374e840febe9f227ad020632b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e939b0a0e64f9096642e93aeccd0ba",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7c43b55865a4fb58ed9a0532f08bf91",
            "value": 3000
          }
        },
        "59a7e361fdb24ea5a1a90c4f3189ca7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9797548d54c443cb91bbf6ae1a9d88ad",
            "placeholder": "​",
            "style": "IPY_MODEL_d1585e5512684ee69bed4cc3015e91fe",
            "value": "Map: 100%"
          }
        },
        "6486d4317f1b4bdcbca2eabf1a8bad3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f58412e1044f7aa0f1256da90f76fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59a7e361fdb24ea5a1a90c4f3189ca7e",
              "IPY_MODEL_38be7f7a4d754b368de499ec2039b7db",
              "IPY_MODEL_cab1d507641b48c08fbbab2401a12e93"
            ],
            "layout": "IPY_MODEL_818b62151a8f4a788c0e8602f9bac520"
          }
        },
        "818b62151a8f4a788c0e8602f9bac520": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "918f913851b645748089ae538e0aaccd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9797548d54c443cb91bbf6ae1a9d88ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4bad9577f64dbd9acc90fb714bf9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63cbeef8691465b9b940bbdb4700350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a92b6aa957474e9597f5235a8621c93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4e2e86fa354427aad7681618b626913",
              "IPY_MODEL_41bc288374e840febe9f227ad020632b",
              "IPY_MODEL_bc4399242fb24381b3185f3f17df9400"
            ],
            "layout": "IPY_MODEL_f112dac7b4c94a9d900036c0cb3eec01"
          }
        },
        "bc4399242fb24381b3185f3f17df9400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4bad9577f64dbd9acc90fb714bf9b5",
            "placeholder": "​",
            "style": "IPY_MODEL_1a2eeb2026b444bdaf964e10286f1f80",
            "value": " 3000/3000 [00:09&lt;00:00, 592.69 examples/s]"
          }
        },
        "cab1d507641b48c08fbbab2401a12e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f3e9f11cd140c099aca4d9954f10e6",
            "placeholder": "​",
            "style": "IPY_MODEL_a63cbeef8691465b9b940bbdb4700350",
            "value": " 35964/35964 [01:14&lt;00:00, 462.13 examples/s]"
          }
        },
        "d1585e5512684ee69bed4cc3015e91fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3f3e9f11cd140c099aca4d9954f10e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c43b55865a4fb58ed9a0532f08bf91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f080dc4d1c164d3bbacd40f84a764ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f112dac7b4c94a9d900036c0cb3eec01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e2e86fa354427aad7681618b626913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6486d4317f1b4bdcbca2eabf1a8bad3e",
            "placeholder": "​",
            "style": "IPY_MODEL_f080dc4d1c164d3bbacd40f84a764ad5",
            "value": "Map: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}